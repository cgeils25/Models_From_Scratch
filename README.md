Hello! This repo will be a collection of exercises in which I'll implement different classical machine learning algorithms from scratch, and then apply these models to both toy and real-world datasets.

To be clear, by "from scratch", I mean that I'm only allowed to use basic addition/subtraction, multiplication/division, and exponents and logarithms. All gradients, loss calculations, and ML algorithms will be hand-written by me. 

My motivation for doing this is both to deepen my understanding of ML math theory as well as strengthening my python data science skillset. This also helps me gain a better intuition for how to translate academic papers into usable code.

Would I ever use these models in practice? Definitely not, as my implementations will lack a lot of optimization and extra functionality I could get from scikit-learn. Nevertheless, I feel much more comfortable using such tools when I understand how they work at a deeper level.

All models will have their own directories, named accordingly, along with a readme explaining the project and what I learned.

I'll also write unit tests for all models and utility functions using pytest. They will be contained in tests/ and will mirror the structure of the project.

Currently, I've completed logistic regression and a linear support vector machine, and I'm currently working on linear regression.
